
- Network 
  - TCP vs UDP
    - ![img.png](network_tcp_vs_udp.png)
  - 流量控制机制 
    - 由接收方控制的、调节发送方生产速度的机制. 
    - 接收能力的变化导致窗口大小的变化，即TCP 流量控制机制
  - 拥塞控制
    - 发送能力的变化导致窗口大小的变化，即 TCP 拥塞控制机制。
    - TCP 不能忽略网络上发生的事，它被设计成一个无私的协议，当网络发送拥塞时，TCP 会自我牺牲，降低发送的数据量。于是，就有了拥塞控制
  - select、poll、epoll区别
    - select
      - select 实现多路复用的方式是，将已连接的 Socket 都放到一个文件描述符集合，然后调用 select 函数将文件描述符集合拷贝到内核里，让内核来检查是否有网络事件产生，检查的方式很粗暴，就是通过遍历文件描述符集合的方式，当检查到有事件产生后，将此 Socket 标记为可读或可写， 接着再把整个文件描述符集合拷贝回用户态里，然后用户态还需要再通过遍历的方法找到可读或可写的 Socket，然后再对其处理。
      - 对于 select 这种方式，需要进行 2 次「遍历」文件描述符集合，一次是在内核态里，一个次是在用户态里 ，而且还会发生 2 次「拷贝」文件描述符集合，先从用户空间传入内核空间，由内核修改后，再传出到用户空间中。
      - select 使用固定长度的 BitsMap，表示文件描述符集合，而且所支持的文件描述符的个数是有限制的，在 Linux 系统中，由内核中的 FD_SETSIZE 限制， 默认最大值为 1024，只能监听 0~1023 的文件描述符。
    - poll
      - poll 不再用 BitsMap 来存储所关注的文件描述符，取而代之用动态数组，以链表形式来组织，突破了 select 的文件描述符个数限制，当然还会受到系统文件描述符限制。
      - poll 和 select 并没有太大的本质区别，都是使用「线性结构」存储进程关注的 Socket 集合，因此都需要遍历文件描述符集合来找到可读或可写的 Socket，时间复杂度为 O(n)，而且也需要在用户态与内核态之间拷贝文件描述符集合
    - epoll
      - epoll 在内核里使用「红黑树」来关注进程所有待检测的 Socket，红黑树是个高效的数据结构，增删改一般时间复杂度是 O(logn)，通过对这棵黑红树的管理，不需要像 select/poll 在每次操作时都传入整个 Socket 集合，减少了内核和用户空间大量的数据拷贝和内存分配。
      - epoll 使用事件驱动的机制，内核里维护了一个「链表」来记录就绪事件，只将有事件发生的 Socket 集合传递给应用程序，不需要像 select/poll 那样轮询扫描整个集合（包含有和无事件的 Socket ），大大提高了检测的效率。
  - 零拷贝
    - sendfile 系统调用实现了零拷贝技术，零拷贝技术的文件传输方式相比传统文件传输的方式，减少了 2 次上下文切换和数据拷贝次数，只需要 2 次上下文切换和数据拷贝次数，就可以完成文件的传输，而且 2 次的数据拷贝过程，都不需要通过 CPU，2 次都是由 DMA 来搬运，使用零拷贝的项目有nginx、kafka。
  - 既然 IP 层会分片，为什么 TCP 层还需要 MSS 呢？
    - MSL 与 TTL 的区别：MSL 的单位是时间，而 TTL 是经过路由跳数。所以 MSL 应该要大于等于 TTL 消耗为 0 的时间，以确保报文已被自然消亡。
    - 那么当如果一个 IP 分片丢失，整个 IP 报文的所有分片都得重传。 因为 IP 层本身没有超时重传机制，它由传输层的 TCP 来负责超时和重传。
    - 经过 TCP 层分片后，如果一个 TCP 分片丢失后，进行重发时也是以 MSS 为单位，而不用重传所有的分片，大大增加了重传的效率。
  - 序列号：
    - 在建立连接时由计算机生成的随机数作为其初始值，通过 SYN 包传给接收端主机，每发送一次数据，就「累加」一次该「数据字节数」的大小。
    - 用来解决网络包乱序问题
  - 确认应答号：
    - 指下一次「期望」收到的数据的序列号，发送端收到这个确认应答以后可以认为在这个序号以前的数据都已经被正常接收。
    - 用来解决不丢包的问题
  -  为什么需要 TIME_WAIT 状态？
    - 主动发起关闭连接的一方，才会有 TIME-WAIT 状态。需要 TIME-WAIT 状态，主要是两个原因：
      - 防止具有相同「四元组」的「旧」数据包被收到
      - 保证「被动关闭连接」的一方能被正确的关闭，即保证最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭
    - TIME_WAIT 过多有什么危害？
      - 如果服务器有处于 TIME-WAIT 状态的 TCP，则说明是由服务器方主动发起的断开请求。过多的 TIME-WAIT 状态主要的危害有两种：
      - 第一是内存资源占用
      - 第二是对端口资源的占用，一个 TCP 连接至少消耗一个本地端口
  - 为什么是三次握手？不是两次、四次？
    - TCP建立连接时，通过三次握手
      - 能防止历史连接的建立
        - 客户端连续发送多次 SYN 建立连接的报文，在网络拥堵情况下：
          - 一个「旧 SYN 报文」比「最新的 SYN 」 报文早到达了服务端 那么此时服务端就会回一个 SYN + ACK 报文给客户端
          - 客户端收到后可以根据自身的上下文，判断这是一个历史连接（序列号过期或超时），那么客户端就会发送 RST 报文给服务端，表示中止这一次连接
      - 能减少双方不必要的资源开销，
        - 如果只有「两次握手」，当客户端的 SYN 请求连接在网络中阻塞，客户端没有接收到 ACK 报文，就会重新发送 SYN ，由于没有第三次握手，服务器不清楚客户端是否收到了自己发送的建立连接的 ACK 确认信号，所以每收到一个 SYN 就只能先主动建立一个连接，这会造成什么情况呢？如果客户端的 SYN 阻塞了，重复发送多次 SYN 报文，那么服务器在收到请求后就会建立多个冗余的无效链接，造成不必要的资源浪费。
      - 能帮助双方同步初始化序列号。 序列号能够保证数据包不重复、不丢弃和按序传
        - TCP 协议的通信双方， 都必须维护一个「序列号」， 序列号是可靠传输的一个关键因素，它的作用：
          - 接收方可以去除重复的数据
          - 接收方可以根据数据包的序列号按序接收
          - 可以标识发送出去的数据包中， 哪些是已经被对方收到的
    - 两次握手：无法防止历史连接的建立，会造成双方资源的浪费，也无法可靠的同步双方序列号
    - 四次握手：三次握手就已经理论上最少可靠连接建立，所以不需要使用更多的通信次数
  - TCP 优化
    - 三次握手
      - SYN重传次数 tcp_sync_retries
      - 绕过三次握手 tcp fastopen
    - 四次挥手
      - FIN重传次数  orphan retries
      - FIN WAIT2的时间（close调用） fin timeout
      - 孤儿链接的上限个数  max orphans
  - CDN
    - 本地 DNS 服务器去请求 CDN 的 GSLB 的域名，GSLB 就会为用户选择一台合适的 CDN 节点提供服务，选择的依据主要有以下几点：
      - 看用户的 IP 地址，查表得知地理位置，找相对最近的 CDN 节点；
      - 看用户所在的运营商网络，找相同网络的 CDN 节点；
      - 看用户请求 URL，判断哪一台服务器上有用户所请求的资源；
      - 查询 CDN 节点的负载情况，找负载较轻的节点；
  - 当服务端出现大量 CLOSE_WAIT 状态的连接的时候，说明服务端的程序没有调用 close 函数关闭连接
    - 我们先来分析一个普通的 TCP 服务端的流程：
      - 1 创建服务端 socket，bind 绑定端口、listen 监听端口
      - 2 将服务端 socket 注册到 epoll
      - 3 epoll_wait 等待连接到来，连接到来时，调用 accpet 获取已连接的 socket
      - 4 将已连接的 socket 注册到 epoll
      - 5 epoll_wait 等待事件发生
      - 6 对方连接关闭时，我方调用 close
    - 可能导致服务端没有调用 close 函数的原因，如下
      - 第 3 步没有做，有新连接到来时没有调用 accpet 获取该连接的 socket，导致当有大量的客户端主动断开了连接，而服务端没机会对这些 socket 调用 close 函数，从而导致服务端出现大量 CLOSE_WAIT 状态的连接。发生这种情况可能是因为服务端在执行 accpet 函数之前，代码卡在某一个逻辑或者提前抛出了异常。
      - 第 4 步没有做，通过 accpet 获取已连接的 socket 后，没有将其注册到 epoll，导致后续收到 FIN 报文的时候，服务端没办法感知这个事件，那服务端就没机会调用 close 函数了。
        - 发生这种情况可能是因为服务端在将已连接的 socket 注册到 epoll 之前，代码卡在某一个逻辑或者提前抛出了异常。之前看到过别人解决 close_wait 问题的实践文章，感兴趣的可以看看：一次 Netty 代码不健壮导致的大量 CLOSE_WAIT 连接原因分析
      - 第 6 步没有做，当发现客户端关闭连接后，服务端没有执行 close 函数，可能是因为代码漏处理，或者是在执行 close 函数之前，代码卡在某一个逻辑，比如发生死锁等等。
  - IO特别密集时epoll效率还高吗
    - 可以考虑select/poll，这种情况轮询也很高效，且结构简单
    - io特别密集时为什么 epoll 效率不高。原因是：
      - 连接密集（短连接特别多），使用epoll的话，每一次连接需要发生epoll_wait->accpet->epoll_ctl调用，而使用select只需要select->accpet，减少了一次系统调用。
      - 读写密集的话，如果收到数据，我们需要响应数据的话，使用epoll的情况下， read 完后也需要epoll_ctl 加入写事件，相比select多了一次系统调用
  - ET模式
    - 边缘触发模式，I/O 事件发生时只会通知一次，而且我们不知道到底能读写多少数据，所以在收到通知后应尽可能地读写数据，以免错失读写的机会。因此，我们会循环从文件描述符读写数据，那么如果文件描述符是阻塞的，没有数据可读写时，进程会阻塞在读写函数那里，程序就没办法继续往下执行。所以，边缘触发模式一般和非阻塞 I/O 搭配使用，程序会一直执行 I/O 操作，直到系统调用（如 read 和 write）返回错误，错误类型为 EAGAIN 或 EWOULDBLOCK。
  - select poll epoll，epoll具体是怎么实现的. epoll为什么这么快，还有优化空间么?如果要你实现一个网络IO应该怎么实现
    - epoll 具有以下优点：
      - 支持一个进程打开的文件描述符数量无限制，而 select/poll 则受限于系统打开文件描述符的最大数量。
      - epoll 采用回调方式，只有就绪的文件描述符才会通知应用程序，而 select/poll 则需要轮询每个文件描述符，效率较低。
      - epoll 采用内核与用户空间共享内存方式，避免了 select/poll 中需要将文件描述符集合从用户空间复制到内核空间的开销。
    - 优化
      - 通过设置 epoll 的阈值，避免在短时间内重复触发事件。
      - 合理设置 epoll 的超时时间，避免无限等待。
      - 使用较新的 Linux 内核版本，因为内核版本的更新通常会带来一些性能优化。
    - epoll中可以无限承载socket的连接吗？创建socket时的返回值是什么？
  - UDP实现可靠协议??
  - 假设这样一个场景，客户端在和服务端进行TCP的三次握手的过程中，突然间客户端宕机了，那么这个socket怎么处理？可以删除吗？是怎么删除的？
    - 那么服务端会一直等待客户端的SYN包，直到超时为止。这个超时时间由操作系统的TCP协议栈决定，通常是几分钟到几小时不等。
    - 在超时之后，服务端会关闭这个socket，释放相关的资源。这个过程中，服务端会向客户端发送一个RST包，表示连接已经被重置。
    - 在这个过程中，客户端并没有真正建立起连接，所以也不需要显式地关闭这个socket。操作系统会在一定时间内自动清理这个socket，释放相关的资源。这个时间通常是几分钟到几小时不等，也由操作系统的TCP协议栈决定。
  - 在服务端调用accept()之后,socket就是一直可读的吗？就是调用read()函数就一直可以读吗？会阻塞吗？
  - 如果服务端read()函数发生了阻塞,对方客户端异常关闭了,一直没有发数据过来,服务端会一直阻塞吗？会导致服务端卡死吗？
  - 一个服务端进程最多可以和多少个客户端进行连接？和fd的数量有关吗？
  - 客户端在和服务端进行TCP的三次握手的过程中，突然间客户端宕机了，那么这个socket怎么处理？可以删除吗？是怎么删除的？
  - 在服务端调用accept()之后,socket就是一直可读的吗？就是调用read()函数就一直可以读吗？会阻塞吗？
  - 如果服务端read()函数发生了阻塞,对方客户端异常关闭了,一直没有发数据过来,服务端会一直阻塞吗？会导致服务端卡死吗？


- Redis
  - map怎么扩容，扩容时会影响缓存吗
    - 底层有两个dict，一个dict负责请求，到达负载比例进行扩容，渐进式扩容，一部分一部分转移到新的dict
  - 扩容时访问key怎么处理?
    - 为了避免 rehash 在数据迁移过程中，因拷贝数据的耗时，影响 Redis 性能的情况，所以 Redis 采用了渐进式 rehash，也就是将数据的迁移的工作不再是一次性迁移完成，而是分多次迁移。
    - 在进行渐进式 rehash 的过程中，会有两个哈希表，所以在渐进式 rehash 进行期间，哈希表元素的删除、查找、更新等操作都会在这两个哈希表进行。比如，查找一个 key 的值的话，先会在「哈希表 1」 里面进行查找，如果没找到，就会继续到哈希表 2 里面进行找到。
    - 另外，在渐进式 rehash 进行期间，新增一个 key-value 时，会被保存到「哈希表 2 」里面，而「哈希表 1」 则不再进行任何添加操作，这样保证了「哈希表 1 」的 key-value 数量只会减少，随着 rehash 操作的完成，最终「哈希表 1 」就会变成空表。
  - redis缓存击穿解决方法
    - 缓存穿透指的是缓存查询的key不存在，数据库也无数据。
    - 解决方法：
      - .接口增加不合法的参数校验。预防调用方恶意传一些不可能存在的数据。
      - DB中查询不到数据的情况，可以将该key对应的value设为null值，或其他特殊值，同时设置短一点的过去时间，以免影响正常情况。该方法可以防止短时间内同一个key进行暴力攻击。
      - .若只是恶意者故意攻击，可以在nginx配置对攻击者ip设置访问阈值。
      - .布隆过滤器，利用高效的数据结构和算法快速判断该key是否存在数据库，不存在就return，存在就去查询DB数据库刷新KV再return。
  - 缓存击穿指的是缓存无数据，数据库有数据，key比较集中。
    - 解决方法：
      - 1.设置热点数据永不过期。
      - 2.热点数据快过期时，通过另一个异步线程重新设置key。      - 
      - 3.当缓存数据过期，重新从数据库加载数据到缓存的过程上互斥锁。
  - 缓存雪崩解决方法
    - 缓存雪崩指的是缓存集合在同一时间段内过期失效或某原因缓存服务器发生宕机，导致大量的缓存击穿，所有请求直接访问数据库。
      - 解决方法：
      - 1.使用缓存集群，保证缓存高可用。
      - 2.使用Hystrix，通过熔断、降级、限流三个手段降低雪崩后发生的损失。
      - 3.设置不同的过期时间。
      - 4.数据预热。在正式部署前，先把可能的数据预先访问一遍，将可能被访问到的数据提前加载到缓存。
  - redis和数据库如何保证一致性
    - -1.延迟双删策略：删除缓存-更新数据库-休眠一段时间-再次删除缓存。休眠是为了在更新完数据库前保证读请求结束，此时读请求的数据是脏数据，然后再一次删除缓存。
    - 2.异步更新缓存（基于订阅binlog的同步机制）：使用canal框架，将redis伪装成mysql的slave节点进行备份请求，从而达到redis缓存更新。
  - skiplist
    - 在Redis5.0的版本下，只要创建了跳表，他就会创建64个头节点，然后在创建节点的时候也判断随机数大小，如果小于0.25，那他的层数加1，然后对应层head就会顺着这层指向他，是这么理解的吗？
      - 他就会创建64个头节点
        - 这个说法是错的，是指创建一个头节点，只是头节点默认的高度就是最高的，例如是 64 或者 32，这是 Redis 跳表的最大高度，定义的常量
      - 然后在创建节点的时候也判断随机数大小，如果小于0.25，那他的层数加1
        - 创建节点的时候，就会随机好节点的高度。例如默认是第一层，然后有 0.25 的概率这个节点会是两层高，有 0.25 * 0.25 的概率会是三层高，此役类推
      - 然后对应层head就会顺着这层指向他
        - 不一定是 head，取决于你在哪个位置插入节点，假设节点随机出来的高度是 n 的话，本质上就是要维护 n 条链表的有序性，即在 n 条链表中插入这个节点。
    - 这个跳表高度最大值怎么 32 -> 64 -> 32 改来改去的
      - 从 64 改回 32，其实本质就是现实生活中基本，没办法碰到这么高层，按照 p = 0.25 的概率来说，正常来说百万个元素就是到达 10 层了，可以再往后算一下，20 层，32 层，需要多少个元素才能达到。目前现实生活中基本没办法撞到（首先内存就会爆炸）。所以才又改回 32，改回 32 可以节省一些内存资源、栈、性能
  - 为什么close文件需要异步？
    - 异步 close 其实就主要用在 aof 部分，用 6.2 版本的 AOFRW 来举例
      - 在子进程重写完成后，会需要父进程收尾做一些善后工作 其中有几项工作是：
        - 将新重写完成的的 AOF 临时文件重命名回 aof 文件 关闭老的 aof 文件. 那么老的 aof 文件需要进行删除。rename new_aof to old_aof 其实就做了这个事情
      - 如果删除的是一个很大的 AOF 文件，会有啥影响？
        - 删除一个大文件/大目录是很慢的 那么对于 Redis 来说，删除文件就意味着会有阻塞风险，主进程肯定是不能说因为删除文件而阻塞在这。
        - 前面的 rename 和 close 都会有阻塞的风险，分别对应于 AOF 开启或者关闭的情景。
        - 当进行 rename 操作大的时候，正常情况来说老 aof 文件会被删除，不过因为 redis 还 open 着老 aof 文件，占有引用，所以这个 rename 操作，不会触发文件的 unlink，此时是正常的但是如果主进程对老 aof 文件进行 close(old_aof_fd)，因为 redis 是最后一个占用 fd 引用的进程，这个 close， 会触发 old aof file 的 unlink，那么就会阻塞主进程。
      - 不过可惜的是这一段逻辑在 7.0 里因为 MP-AOF 引入给干掉了，随之而去的还有 AOFRW 里管道的用法
  - 主从复制问题 多个buffer问题
    - buffer实际上就是客户端的输出缓冲区，每个从连接上来后，就是一个 client，跟我们正常 redis cli连接上来的客户端是一个意思，只是从的话更多我们叫 slave replica 会有 flag 标识它是从命令传播，主服务器，都是将命令写到从客户端的输出缓冲区，也就是这个 replication buf 。
    - 输出缓冲区的概念是每个客户端都会有，只是对于主从复制来说，这边我们叫它 buffer，如果知道是输出缓冲区，知道是也是个客户端，可能会更好理解一点，为什么每个 slave 都会有一个
    - 当然这的确是，内存上有点浪费，所以在 7.0 被改成了，全局共享复制缓冲区，复制积压缓冲区 和 所有从服务器的复制buf， 都是共享的了
  - 用Go实现redis的优势在哪里呢
    - redis 采用单线程内核设计极大的降低了开发难度同时也牺牲了性能，单线程应该说是一种「取舍」或者「设计理念」而不能简单的当做优势。
    - Dragonfly 就采用面向并发、面向多核的设计取得了比 Redis 高很多的性能。使用 Go 语言开发内存数据库并发挥其高并发优势并无不妥。
    - 内存数据库的瓶颈往往在 IO 上而不在其内核的处理速度上。目前 Godis 受 netpoller 性能限制确实没有发挥出其并发内核的优势，这就需要未来换用 io_uring 等更先进的模型来解决了。
  - 缓存热 key 怎么解决
  - Redis slowlog 原理
  - Redis的持久化机制
  - 基于 Redis 的分布式锁会有什么问题
    - 主从模型下同步不保证一致会导致锁失效
  - Redis 分布式锁超时可以超时时间设长一点可以吗？不可以的话需要怎么解决？
    - 不根本解决问题，可以考虑旁路的 goroutine 不断自旋续期
  - https://docs.qq.com/doc/DRXpXSEh6S0VmUFZD?u=cd4fd4c4ef494951aa47b3cc433a1115
  - 基于 Redis 实现分布式锁：
    - 如何基于 Redis 实现一个最简易的分布式锁？
    - 为什么要给锁设置一个过期时间？
    - 如何实现锁的优雅续期？
    - 如何实现可重入锁？
    - Redis 如何解决集群情况下分布式锁的可靠性？
  - 基于 ZooKeeper 实现分布式锁：
    - 如何基于 ZooKeeper 实现分布式锁？
    - 为什么要用临时顺序节点？
    - 为什么要设置对前一个节点的监听？
    - 如何实现可重入锁？

- Mysql
  - MySQL的索引
    - 根据数据结构分类：B+树索引，Hash索引，全文索引；Hash索引O(1)查找，B+树是O(log n)查找，B+树支持范围查找。
    - 根据存储分类：聚集索引和非聚集索引
  - MVCC
    - InooDB是通过 MVCC 实现可重复读的隔离级别的，MVCC 就是多版本并发控制，它其实记录了历史版本的数据，解决了读写并发冲突问题。
    - 有一个版本编码，然后它进入了各种操作下的数据状态，能够根据当前这个指令的状态来读取不同时期的数据快照。主要实现方法的话就是通过事务版本号，读取视图还有undo日志进行完善的。
  - 原子性怎么实现的
    - 事务的原子性是通过 undo log 实现的。
    - undo log 是一种用于撤销回退的日志。在事务没提交之前，MySQL 会先记录更新前的数据到 undo log 日志文件里面，当事务回滚时，可以利用 undo log 来进行回滚
  - 持久性是怎么实现的
    - 事务的持久性是通过  redo log  实现的。
    - 我们修改某条记录，其实该记录并不是马上刷入磁盘的，而是将 Innodb 的 Buffer Pool  标记为脏页，等待后续的异步刷盘。
    - InnoDB 引擎会在适当的时候，由后台线程将缓存在 Buffer Pool 的脏页刷新到磁盘里，这就是 WAL （Write-Ahead Logging）技术。
      - WAL 技术指的是， MySQL 的写操作并不是立刻写到磁盘上，而是先写日志，然后在合适的时间再写到磁盘上。
    - redo log 是物理日志，记录了某个数据页做了什么修改，比如对 XXX 表空间中的 YYY 数据页 ZZZ 偏移量的地方做了AAA更新，每当执行一个事务就会产生这样的一条或者多条物理日志。
  - Index
    - index(abc)
      - select * from T where a=x and b=y and c=z
      - select * from T where a=x and b>y and c=z
      - select * from T where c=z and a=x and b=y
      - select (a,b) from T where a=x and b>y
      - select count(*) from T where a=x
      - select count(*) from T where b=y
      - select count(*) form T
    - a、b、c三个字段都可以走联合索引
    - a和b都会走联合索引，但是由于最左匹配原则， 范围查找后面的字段是无法走联合索引的，但是在 mysql 5.6 版本后，c 字段虽然无法走联合索引，但是因为有索引下推的特性，c 字段在, inndob 层过滤完满足查询条件的记录后，才返回给server 层进行回表，相比没有索引下推，减少了回表的次数。
    - 查询条件的顺序不影响，优化器会优化，所以a、b、c三个字段都可以走联合索引
    - a和b都会走联合索引，查询是覆盖索引，不需要回表
    - a 可以走联合索引
    - 只有b，无法使用联合索引，由于表存在联合索引，所以 count(*) 选择的扫描方式是扫描联合索引来统计个数，扫描的方式是type=index
    - 由于表存在联合索引，所以 count(*) 选择的扫描方式是扫描联合索引来统计个数，扫描的方式是type=index
    - 关于 count(*) 为什么选择扫描联合索引（二级索引），而不扫描聚簇索引的原因：这是因为相同数量的二级索引记录可以比聚簇索引记录占用更少的存储空间，所以二级索引树比聚簇索引树小，这样遍历二级索引的 I/O 成本比遍历聚簇索引的 I/O 成本小，因此「优化器」优先选择的是二级索引。
    - 比如说有一个语句是where x=a and y=b and z=c,你怎么建索引
    - 那比如说再来一个wherey=a and z=b呢,你怎么建索引
    - 那么第一个条件where x=a and y=b and z=c会用到哪些索引
    - 那比如说有一个语句是where y=a and z between b and c,你怎么建索引
    - 那么where y=a and z between b and c and x=d会用到哪些索引
  - binlog
    - binlog日志是MySQL数据库的一种日志记录机制，用于记录数据库的修改操作（如插入、更新、删除等），以便在需要时进行数据恢复、数据复制和数据同步等操作。
    - binlog日志的实现以下功能：
      - 数据恢复：binlog日志可以用于回滚到之前的某个时间点，从而恢复数据。
      - 数据复制：binlog日志可以用于在主从数据库之间复制数据，从而实现数据的高可用和负载均衡等功能。
  - binlog，redolog和undolog的区别
    - binlog（二进制日志）：记录所有对MySQL数据库的修改操作，包括插入、更新和删除等。
      - binlog主要用于数据恢复到指定时间点或者指定事务。可以使用mysqlbinlog命令将binlog文件解析成SQL语句，从而恢复MySQL数据库的状态。
    - redolog（重做日志）：记录所有对MySQL数据库的修改操作，但是只记录了物理操作，比如页的修改。
      - redolog主要用于MySQL的崩溃恢复，即在MySQL崩溃后，通过重做日志，将数据库恢复到最近一次提交的状态。可以使用 Forcing InnoDB Recovery 来进行崩溃恢复。
    - undolog（回滚日志）：用于记录事务的回滚操作，即在事务执行过程中，如果发生了回滚，会将回滚操作记录到undolog中。
      - undolog主要用于 MySQL 的回滚操作，比如使用ROLLBACK语句回滚事务。undolog是InnoDB存储引擎的特有日志，不同于其他存储引擎。
  - binlog和redolog做数据恢复的区别
    - binlog是MySQL的二进制日志，它记录了所有对MySQL数据库的修改操作，包括插入、更新和删除等。
      - binlog可以用于恢复MySQL数据库到指定的时间点或者指定的事务。具体来说，可以使用mysqlbinlog命令将binlog文件解析成SQL语句，然后再执行这些SQL语句，从而恢复MySQL数据库的状态。
    - redolog是MySQL的重做日志，它记录了所有对MySQL数据库的修改操作，但是只记录了物理操作，比如页的修改。
      - redolog可以用于恢复MySQL数据库的崩溃恢复，即在MySQL崩溃后，通过重做日志，将数据库恢复到最近一次提交的状态。具体来说，可以使用innodb_recovery命令来进行崩溃恢复，该命令会根据重做日志来恢复数据库。
    - 因此，binlog和redolog都可以用于数据恢复，但是它们的使用场景和恢复方法有所不同。binlog主要用于数据恢复到指定时间点或者指定事务，而redolog主要用于MySQL的崩溃恢复。
  - 可重复读是是什么意思，怎么实现的
    - 同一个事务中多次读取结果一致。通过Read View + MVCC实现，在事务开始时创建一个Read View，之后都用这个Read View
  - 可重复读具体实现细节
    - Read View 中四个字段作用；
      - m_ids ：指的是在创建 Read View 时，当前数据库中「活跃事务」的事务 id 列表，注意是一个列表，“活跃事务”指的就是，启动了但还没提交的事务。
      - min_trx_id ：指的是在创建 Read View 时，当前数据库中「活跃事务」中事务 id 最小的事务，也就是 m_ids 的最小值。
      - max_trx_id ：这个并不是 m_ids 的最大值，而是创建 Read View 时当前数据库中应该给下一个事务的 id 值，也就是全局事务中最大的事务 id 值 + 1；
      - creator_trx_id ：指的是创建该 Read View 的事务的事务 id。
    - 聚簇索引记录中两个跟事务有关的隐藏列
      - trx_id，当一个事务对某条聚簇索引记录进行改动时，就会把该事务的事务 id 记录在 trx_id 隐藏列里；
      - roll_pointer，每次对某条聚簇索引记录进行改动时，都会把旧版本的记录写入到 undo 日志中，然后这个隐藏列是个指针，指向每一个旧版本记录，于是就可以通过它找到修改前的记录。
  - 覆盖索引首先需要了解主键索引和辅助索引。
    - 主键索引：叶子结点保存的是数据；
    - 辅助索引：叶子结点保存的是主键值。
    - 回表：由于辅助索引保存的是主键值，如果使用辅助索引搜索数据就必须先从辅助索引取到主键值，再使用主键的值去主键索引上查询，直到找到叶子结点上的数据返回。
    - 覆盖索引：辅助索引的叶子结点直接保存的是我们需要的数据，则称为覆盖索引。
  - 如何提高数据库查询效率
    - 1.应尽量避免全表扫描，应先考虑在where或order by涉及的列上建立索引。（可以使用explain关键词对SQL语句性能分析）
    - 2.应尽量避免在where子句中对字段进行null值判断。
    - 3.并非所有索引对查询都有效，SQL是根据表中数据来进行查询优化的，当索引列有大量数据重复时，查询可能不会去利用索引。
    - 4.尽量使用数字型字段，若只含数值信息的字段，尽量不要设计为字符型，这会降低查询和连接的性能，并会增加存储开销。这是因为引擎在处理查询和连接时会逐个比较字符串中每一个字符，而对于数字型而言只需要比较一次即可。
    - 5.尽可能使用varchar/nvarchar代替char/nchar，因为可变长类型字段存储空间小，可以节省存储空间，其次对于查询来说，在一个相对较小的字段内搜索效率显然要高。
  - 原子性怎么保证的
    - undo log（回滚日志）保证了事务的 ACID 特性中的原子性（Atomicity）。
    - undo log 是一种用于撤销回退的日志。在事务没提交之前，MySQL 会先记录更新前的数据到 undo log 日志文件里面，当事务回滚时，可以利用 undo log 来进行回滚。
  - 假如我们现在对已经插入了一条数据，我们接下来去修正另外一条数据。被查入的这条数据在这个时候能够被查询到吗？
    - 要看数据库的隔离级别
      - 在「读未提交」隔离级别下，可能发生脏读、不可重复读和幻读现象；
      - 在「读提交」隔离级别下，可能发生不可重复读和幻读现象，但是不可能发生脏读现象；
      - 在「可重复读」隔离级别下，可能发生幻读现象，但是不可能脏读和不可重复读现象；
      - 在「串行化」隔离级别下，脏读、不可重复读和幻读现象都不可能会发生。
  - mysql有三种日志文件，
    - redo log 重做日志，确保事务的持久性
    - undo log 回滚日志，确保事务的原子性，用于回滚事务，同时提供mvcc下的非锁定读
    - bin log 二进制日志，用于主从复制场景下，记录master做过的操作
    - relay log 中继日志，用于主从复制场景下，slave通过io线程拷贝master的bin log后本地生成的日志
    - 慢查询日志，用于记录执行时间过长的sql，需要设置阈值后手动开启
  - b+树是怎么组织数据的，数据的顺序一定是从左到右递增的么? ⻚分裂伪代码，b+树的倒数底层层可以⻚分裂么
  - innodb二次写是什么
  - mysql一⻚最大能存多少数据
  - myisam和innodb索引上的区别
  - innodb commit之前，redo 的prepare然后binlog commit，然后redo再commit有 什么缺点?5.6之后是怎么优化的?
  - myisam为什么不支持事务，如果要支持事务要怎么做
  - 可重复读是怎么解决脏读和不可重复读问题的？
  - MVCC是如何解决脏读和不可重复读问题的呢？
  - MVCC是如何与ReadView的属性进行比较的?


- Database
  - NoSQL和关系型数据库的区别
    - 数据模型：关系型数据库采用表格模型来存储数据，表格中的每行都代表一个记录，每列代表一个属性或字段。而NoSQL数据库则采用不同的数据模型，如文档、键值对、图形和列式等。
    - 数据结构：关系型数据库的数据结构严格，要求每个表都必须有一个预定义的模式（schema），包括数据类型、大小、关系等。而NoSQL数据库没有这种限制，允许数据结构的动态变化。
    - 可扩展性：NoSQL数据库通常具有很好的可扩展性，可以通过添加更多的节点来水平扩展，以应对大规模数据处理和高并发访问的需求。关系型数据库也可以进行垂直扩展，即增加更多的处理能力和存储空间，但这种方式的扩展存在一定的局限性。
    - ACID特性：关系型数据库通常具有ACID特性（原子性、一致性、隔离性和持久性），它们可以确保数据的完整性和一致性。而NoSQL数据库通常不支持完全的ACID特性，但提供了更高的可用性和性能。
    - 查询语言：关系型数据库通常使用SQL语言来查询和操作数据，这种语言简单易学，能够完成复杂的数据查询和统计分析。而NoSQL数据库则使用不同的查询语言，如MongoDB的Mongo Query和Cassandra的CQL等。
  - 线上是如何分表分库的，用什么做分表分库的策略，跨表查询
  - 什么场景下索引会失效？
    - 场景有很多，但是如果我是一个引擎，我关注的不是什么情况会失效，而是走什么路径所花费的随机 I/O 和顺序 I/O 最少，如果走某个索引花费的随机 I/O 比从聚簇索引（顺序）查（成本）都还要高，那还不如直接去全表扫描；
    - 典型例子：捞超过全表 30% 的数据；比如说我要按照 update_time 去做范围查询，捞很多的数据，即使 update_time 有索引，也会选择全表扫描；
  - 了解索引下推吗？什么情况下会下推到引擎去处理？
    - 通过某个索引没办法按顺序地覆盖所有的查询条件，但是仍然可以利用索引内存在的字段（尽管不是有序的，需要扫描）去进一步过滤；
    - 索引下推（Index Pushdown）是一种优化技术，用于在数据库查询中减少数据的读取量，从而提高查询效率。当数据库系统接收到查询请求时，它会尝试将查询条件下推到存储引擎中的索引层级，以便在索引层级中过滤掉不符合条件的数据，从而减少需要读取的数据量。
    - 当查询条件中包含索引列时，存储引擎会尝试将查询条件下推到索引层级中，以便在索引层级中过滤掉不符合条件的数据，从而减少需要读取的数据量。
    - 当查询条件中包含与索引列相关的表达式时，存储引擎会尝试将表达式下推到索引层级中，以便在索引层级中过滤掉不符合条件的数据，从而减少需要读取的数据量。
    - 举例：idx(a,b,c,d)，查询条件为 a=? and b=? and d=?，发生下推减少回表数量；
  - WHERE id NOT IN (?, ?, ?) 会走索引吗？
    - 要看成本 - id 字段只包含 3 个值，1、2、3，3 只有几行，而 1、2 各有 100w 行，如果查询条件是 NOT IN (1, 2) 会走索引，如果查询条件是 NOT IN (3) 不会走索引。
  - 假如说我在数据库读取出来的数据乱码了怎么办
    - 你的数据库一般使用什么编码格式
    - 如果数据库编码格式没有问题，但是你的程序读出来还是乱码怎么办
  - 数据库迁移过程中双读双写具体是什么样的方案？
    - 双写过程中只写成功了其中一个 DB，返回给用户报错，那是否会存在脏数据呢？
    - 双读具体是什么方案，其中一个读成功了就返回还是要两个都读成功才可以？


- Java
  - syncronized是怎么实现的
    - 使用monitorenter和monitorexit，在对象头进行加锁
    - 补充：最好把锁升级的过程都讲清楚
  - volatile实现什么能力，怎么实现的
    - 可见性，CPU core分别有自己的cache，彼此之间不可见，使用volatile会强制将cache写入主存，和从主存加载数据
    - 补充：还有禁止指令重排，当一个变量被volatile修饰时，编译器和处理器会禁止对其进行指令重排序，从而保证程序的正确性
  - java匿名类和lambda表达式为什么要将变量final
    - final是不可变的，线程安全，避免共享变量被其他线程修改
  - 抽象类和接口的区别

- C++
  - shared_ptr的原理
    - shared_ptr使用引用计数，每一个shared_ptr的拷贝都指向相同的内存
    - 每使用他一次，内部的引用计数加1，每析构一次，内部的引用计数减1，减为0时，自动删除所指向的堆内存。
    - shared_ptr内部的引用计数是线程安全的，但是对象的读取需要加锁。
    - 一个最大的陷阱是循环引用，循环引用会导致堆内存无法正确释放，导致内存泄漏，可以通过 weak_ptr 来解决这个问题。
  - 多线程怎么保证引用计数的安全的
    - 引用计数这个变量是std::atomic，操作时自带锁
  - 存字符串用unordered_map还是用map好
  - new和malloc的理解
    - 分配内存的位置：malloc是从堆上动态分配内存，new是从自由存储区为对象动态分配内存。自由存储区的位置取决于operator new的实现。自由存储区不仅可以为堆，还可以是静态存储区，这都看operator new在哪里为对象分配内存。
    - 返回类型安全性：malloc内存分配成功后返回void*，然后再强制类型转换为需要的类型；new操作符分配内存成功后返回与对象类型相匹配的指针类型；因此new是符合类型安全的操作符。
    - 内存分配失败返回值：malloc内存分配失败后返回NULL。new分配内存失败则会抛异常（bac_alloc）。
    - 分配内存的大小的计算：使用new操作符申请内存分配时无须指定内存块的大小，编译器会根据类型信息自行计算，而malloc则需要显式地指出所需内存的尺寸。
    - 是否可以被重载：opeartor new /operator delete可以被重载。而malloc/free则不能重载。
  - 如果new内存失败了会是怎么样？
    - 会抛出std::bad_alloc异常 如果加上std::nothrow关键字，A* p = new (std::nothrow) A;，new 就不会抛出异常而是会返回空指针。
  - 空类对象的大小 编译器会给每个空类分配一定的空间，通常是1字节：
  - C++中为什么要引进nullptr
    - 类型安全性：nullptr是一种特殊的空指针类型，可以与整数类型区分开来，可以避免将整数0错误地解释为空指针。
    - 重载决议：nullptr可以与其他指针相关的重载函数进行区分。例如，如果有两个函数重载，一个接受整数参数，另一个接受指针参数，传递nullptr将调用接受指针参数的函数：
  - delete a; delete是怎么知道需要释放的指针a指向的对象的大小的
  - 如果申请了内存但忘记释放会造成内存泄漏，用什么方法避免（智能指针）
  - 知道weak_ptr吗，能不能实现weak_ptr
    - weak_ptr 主要是用来解决 shared_ptr 循环引用问题，除了解决相互引用的问题，weak_ptr还适用一切应该不具有对象所有权，又想安全访问对象的情况。
    - 需要内部管理一个引用计数类，并且weak_ptr 接受一个 shared_ptr 进行构造，然后和 shared_ptr 共享一个引用计数类， weak_ptr 的复制和拷贝只增加 weak_count (弱引用)，在解引用之前，需要通过 lock 函数获取一个 shared_ptr ，如果 use_count 计数已经清零，则 lock 返回 nullptr。

- Python
  - python多线程、多进程。
  - python的装饰器怎么实现的

- Go
  - Make和New的区别
  - Panic没被Recover怎么处理
  - gin框架路由怎么实现的，具体正则怎么匹配?限流中间件怎么实现
  - 直接撸码 (三个goroutine顺序打印)
  - golang的关键字defer、recover、pannic之类的实现 原理
  - channel是怎么收发消息的，channel的recq和g是怎么建立关系 的
  - channel 底层数据结构是怎样的，尝试用结构体来表述一下？
  - go的网络IO为什么快?还有优化空间么
    - WHY
      - Goroutine
      - 非阻塞 IO
      - 内存分配：Go 语言的内存分配采用了类似于 JVM 的垃圾回收机制，可以自动回收不再使用的内存，从而避免了内存泄漏和内存溢出的问题。
    - 优化
      - 调整 Goroutine 数量：如果 Goroutine 数量过多，会导致 CPU 调度开销增加，从而降低网络 IO 的效率，因此需要根据实际情况调整 Goroutine 数量。
      - 使用更快的网络库：Go 语言的标准库中的网络库已经非常快了，但是还有一些第三方网络库，例如 fasthttp
      - 使用更快的协议
  - Map 的 panic 能被 recover 掉吗？了解 panic 和 recover 的机制吗
    - map会检测是否存在并发写. 如果检测到并发写会调用runtime.throw()，无法被recover()，直接GG
  - Map 怎么知道自己处于竞争状态？是 Go 编码实现的还是底层硬件实现的？
    - 通过结构体中的标记位实现的，可能是通过 CAS 操作的；- CAS 具体是怎么实现的呢？
  - Go 里面使用 Map 时应注意问题和数据结构
    - 可以通过定义 value 为 struct 来节约内存；哈希分桶的结构，用哈希值的高八位和低八位分别来做桶内定位的依据和分桶的依据等；
  - 并发使用 Map 除了加锁还有什么其他方案吗？
    - 有对比过 sync.Map 和加锁的区别吗？
  - 如果并发环境想要用这种哈希容器有什么方案？
    - sync.Mutex / sync.RWMutex
    - sync.Map
  - 加锁存在什么问题呢？
  - sync.Map 比加锁的方案好在哪里，它的底层数据结构是怎样的？
    - sync.Map是如何实现如此高的读取性能的呢？简单说：空间换时间+读写分离+原子操作(快路径)。
    - 底层使用了两个原生map，一个叫read，仅用于读；一个叫dirty，用于在特定情况下存储最新写入的key-value数据:
    - read(这个map)好比整个sync.Map的一个“高速缓存”，当goroutine从sync.Map中读取数据时，sync.Map会首先查看read这个缓存层是否有用户需要的数据(key是否命中)，如果有(命中)，则通过原子操作将数据读取并返回，这是sync.Map推荐的快路径(fast path)
    - sync.Map 的 Load() 方法流程
      - Load() 方法首先会获取 sync.Map 内部的读锁，以确保在访问 map 中的数据时不会被其他 goroutine 干扰。如果此时有其他 goroutine 正在写入 sync.Map，则 Load() 方法会阻塞，直到写入操作完成
      - Load() 方法接着会在 sync.Map 中查找指定的键，并返回其对应的值。如果指定键不存在，则 Load() 方法会返回一个零值和一个布尔值，表示该键不存在
      - Load() 方法完成后，会释放 sync.Map 的读锁，以便其他 goroutine 可以读取或写入 map
    - sync.Map Store() 如何保持缓存层和底层 Map 数据是相同的
  - Golang 标准库中 map 极端情况下有很多哈希冲突，Golang 标准库如何去避免最坏的查询时间复杂度？
    - Map 的内部实现是使用哈希表（Hash Table）来存储键值对的。当 Map 中的元素数量增加时，哈希表的负载因子会增大，这会导致哈希表的性能下降。为了避免这种情况，Go 语言会在 Map 中元素数量达到一定阈值时触发 Rehash 操作，即重新构建一个更大的哈希表，并将原有的键值对重新散列到新的哈希表中。
      - Go 语言中的 Map 会在以下两种情况下触发 Rehash 操作：
       - 当 Map 中元素数量达到哈希表容量的 6.5/10 时，会触发 Rehash 操作，将哈希表容量扩大一倍
       - 当插入新元素时，如果发现当前哈希表的负载因子已经达到了 12.5/10，也就是哈希表中的元素数量已经达到了容量的 80%，那么会触发 Rehash 操作，将哈希表容量扩大一倍。
    - Golang map Rehash 的策略是怎样的？什么时机会发生 Rehash？
    - Rehash 具体会影响什么？哈希结果会受到什么影响？
      - rehash 操作会影响 Map 的性能。由于重新计算键的哈希值，rehash 操作会消耗一定的计算资源。
      - 此外，在 rehash 过程中，原始哈希表的所有键值对都需要复制到新的哈希表中，因此 rehash 操作还会消耗一定的内存空间和时间
      - rehash 操作不会直接影响哈希结果。哈希结果是由哈希函数计算得出的，与 Map 中元素的数量和布局无关。
      - rehash 操作只会影响哈希表的布局，即每个键在哈希表中的位置会发生变化，但是每个键的哈希值并不会改变
    - Rehash 过程中存放在旧桶的元素如何迁移？
      - Go 标准库中的哈希表实现采用了增量式 rehash 策略，在扩容和收缩时只会处理一部分元素，避免一次性处理过多元素导致性能下降。
      - 当 Map 中的元素数量超过了负载因子（load factor）和哈希表容量的乘积时，map 就会触发扩容操作。在 Go 中，负载因子默认为 6.5。
      - Go Map 在扩容时会创建一个新的哈希表，并将原来的键值对重新散列到新的哈希表中。为了减少哈希冲突，新哈希表的容量是原来的两倍，并且容量一定是 2 的幂次方。
      - 在重新散列过程中，Go Map 会根据哈希值将原来的键值对分配到新哈希表中的对应位置上。如果两个键值对的哈希值相同，会使用链式哈希表（chained hash       - table）的方式进行处理，将它们放在同一个桶（bucket）中。
      - 一旦所有的键值对都已经重新散列到新的哈希表中，Go Map 就会将原来的哈希表释放掉，将新的哈希表作为 Map 的内部存储结构
    - [Map 使用时需要注意哪些问题](https://juejin.cn/post/7226153290051141692)
      - Map 的键必须是可比较的类型，如整数、字符串和指针等，但是切片、函数和结构体等类型是不可比较的，因此不能用作键。
      - Map 中的元素是无序的，这意味着遍历 Map 时，元素的顺序可能会随机改变。
      - Map 的容量是动态变化的，它会自动调整容量以适应新的元素。
      - 如果使用未初始化的 Map，会导致运行时错误。需要使用 make() 函数来初始化 Map。
      - Map 在并发环境下不是安全的。如果需要在并发环境下使用 Map，需要使用 sync 包中提供的锁机制来保护 Map。
    - Map 的 panic 能被 recover 吗?
      - 不能，并发读写 Map 也是很容易遇到的问题
      - map会检测是否存在并发写如果检测到并发写会调用runtime.throw() 函数抛出异常，这种异常是无法在业务代码中通过 recover 捕获的，直接 error。这点最为致命。如果要并发写 map 必须在业务层面上加锁（sync.Mutex或sync.RWMutext）或使用sync.Map
    - sync.Map 和加锁的区别是什么
      - sync.Map 不需要在并发访问时进行加锁和解锁操作。相比之下，使用锁需要在并发访问时显式地加锁和解锁，以避免竞争条件和数据竞争问题
      - 当多个 goroutine 同时访问 sync.Map 时，它会自动分配不同的段来存储数据，并且每个段都有自己的读写锁，以避免竞争条件。这种方式可以提高并发性能，减少开销，并且避免死锁等问题


- 操作系统
  - 死锁
    - 死锁问题的产生是由两个或者以上线程并行执行的时候，争夺资源而互相等待造成的。
    - 死锁只有同时满足互斥、持有并等待、不可剥夺、环路等待这四个条件的时候才会发生。所以要避免死锁问题，就是要破坏其中一个条件即可，最常用的方法就是使用资源有序分配法来破坏环路等待条件。

  - CSP和Actor分布式模型的区别
    - CSP（Communicating Sequential Processes）和Actor都是常见的并发编程模型，它们都可以用于构建分布式系统。它们的主要区别在于它们对于并发性的处理方式不同。
    - CSP模型是基于通信的，它强调各个进程之间通过通信来协调完成任务。在CSP模型中，进程之间是相互独立的，它们通过发送和接收消息来进行通信，而不是共享内存。这种方式可以避免共享内存带来的并发问题，例如死锁和竞争条件。
    - 相比之下，Actor模型是基于状态的，它强调各个进程之间通过改变状态来协调完成任务。在Actor模型中，每个进程都有自己的状态，进程之间通过发送消息来改变状态。这种方式可以避免共享内存的问题，但可能会导致竞争条件和死锁。
    - 因此，CSP模型更适合需要高度并发的场景，例如网络通信和高性能计算。而Actor模型更适合需要维护状态的场景，例如用户界面和游戏引擎。
    - In CSP, processes synchronize when messages are received (i.e. a message cannot be sent from one process unless another process is in a receiving mode), while the Actor model is inherently asynchronous (i.e. messages are immediately sent to other processes' address, irrespective of whether they're actively waiting on a message or not).
  - BIO、NIO和AIO
    - BIO是同步阻塞IO，在进行IO操作时，必须等待IO操作完成后才能进行下一步操作，这时线程会被阻塞。BIO适用于连接数比较小且固定的架构，由于线程阻塞等待IO操作，所以并发处理能力不强。
    - NIO是同步非阻塞IO，可以支持多个连接同时进行读写操作，因此可以用较少的线程来处理大量的连接。NIO通过Selector来监听多个Channel的状态，当Channel中有数据可读或可写时，Selector会通知程序进行读写操作。NIO适用于连接数多且连接时间较短的场景。
    - AIO是异步非阻塞IO，与NIO不同的是，AIO不需要用户线程等待IO操作完成，而是由操作系统来完成IO操作，操作系统完成IO操作后会通知用户线程处理。AIO适用于连接数较多且连接时间较长的场景，如高性能网络服务器等。
  - 你说一下NIO是如何实现同步非阻塞的？主线程是只有一个嘛？
    - 在NIO中，使用了多路复用器Selector来实现同步非阻塞的IO操作。Selector是一个可以监控多个通道（Channel）是否有数据可读或可写的对象，当一个或多个Channel准备好读或写时，Selector会通知程序进行读写操作，而不是像BIO一样阻塞等待IO操作完成。
    - 在NIO中，主线程通常只有一个，但是可以使用Selector来管理多个Channel，实现多个连接的非阻塞读写操作。当有多个Channel需要进行IO操作时，Selector会轮询这些Channel，检查它们的状态是否可读或可写，如果有可读或可写的Channel，就将其加入到一个已选择键集合中，等待程序处理。这样，一个线程就可以同时处理多个Channel，提高了系统的并发处理能力。
  - 一个操作系统，我们在衡量它的内存占用的时候，它一般会有哪些内存的部分
    - free命令的理解 ： available = free + buffer + cache
    - buff/cache都表示什么
  - 主机的内存做一些清理的动作。你知道这里面会涉及到对哪些内存区域进行操作吗
    - 主要有两类内存可以被回收，而且它们的回收方式也不同。
      - 文件页（File-backed Page）：内核缓存的磁盘数据（Buffer）和内核缓存的文件数据（Cache）都叫作文件页。大部分文件页，都可以直接释放内存，以后有需要时，再从磁盘重新读取就可以了。而那些被应用程序修改过，并且暂时还没写入磁盘的数据（也就是脏页），就得先写入磁盘，然后才能进行内存释放。所以，回收干净页的方式是直接释放内存，回收脏页的方式是先写回磁盘后再释放内存。
      - 匿名页（Anonymous Page）：这部分内存没有实际载体，不像文件缓存有硬盘文件这样一个载体，比如堆、栈数据等。这部分内存很可能还要再次被访问，所以不能直接释放内存，它们回收的方式是通过 Linux 的 Swap 机制，Swap 会把不常访问的内存先写到磁盘中，然后释放这些内存，给其他更需要的进程使用。再次访问这些内存时，重新从磁盘读入内存就可以了。
    - 文件页和匿名页的回收都是基于 LRU 算法，也就是优先回收不常访问的内存。LRU 回收算法，实际上维护着 active 和 inactive 两个双向链表，其中：
      - active_list 活跃内存页链表，这里存放的是最近被访问过（活跃）的内存页；
      - inactive_list 不活跃内存页链表，这里存放的是很少被访问（非活跃）的内存页；
      - 越接近链表尾部，就表示内存页越不常访问。这样，在回收内存时，系统就可以根据活跃程度，优先回收不活跃的内存。
  - 从 a 文件 copy 到另外一个目录， b 作为一个从 a 目录 copy 到一个 b 目录这样的一个文件，操作过程中间包含了哪些系统调用？这里面执行了多少次拷贝的动作？
    - 在另外一个目录创建a文件，然后通过read读取原来a文件的数据，然后write写入到新目录的a文件。发生了 4 次数据拷贝，其中两次是 DMA 的拷贝，另外两次则是通过 CPU 拷贝的。
    - 第一次拷贝，把磁盘上的数据拷贝到操作系统内核的缓冲区里，这个拷贝的过程是通过 DMA 搬运的。
    - 第二次拷贝，把内核缓冲区的数据拷贝到用户的缓冲区里，于是我们应用程序就可以使用这部分数据了，这个拷贝到过程是由 CPU 完成的。
    - 第三次拷贝，把刚才拷贝到用户的缓冲区里的数据，再拷贝到内核缓冲区里，这个过程依然还是由 CPU 搬运的。
    - 第四次拷贝，把内核缓冲区里的数据，拷贝到磁盘，这个过程又是由 DMA 搬运的。
  - linux进程创建线程的流程是怎么样的？
  - 线程共享进程的资源在linux中是怎么实现的？
  - 线程有自己私有的栈，那么这个栈的内存是被分配到哪里的？是放在进程所属的内存里面，还是说放在独立于进程外部的内存中？
  - Windows和linux的fs有什么区别
  -  什么是超级块，超级快存储在哪儿
  - Linux的vfs和fs是什么关系，核心如何实现
  - 一次write（fd, flag）函数调用从用户态到磁盘的流程
  - 磁盘io负载怎么查看，一般什么情况负载会满，满载的时候如何确定是哪个进程占用了io
  - 磁盘碎片是什么，linux需要进行碎片整理么
  - 文件系统为何有一个保留空间？这个大小默认是多少，何时需要调节
  - 文件系统如何保证断电不丢数据（崩溃一致性）
  - mmap和write的区别

- MQ 
  - 怎么解决消息队列上的消息堆压？
    - （1）自身场景下，消息堆压是暂时的，消息堆压只是突发状况，就算不额外处理，随着时间流逝也可消费完毕。
    - （2）假如存在持续性消息堆压，可以考虑临时增加消费者的数量，提升消费者的消费能力。
    - 降级一些非核心的业务。通过扩容和降级承担流量，这是为了表明你对应急问题的处理能力
    - 排查解决异常问题，如通过监控，日志等手段分析是否消费端的业务逻辑代码出现了问题，
  - RabbitMq消息阻塞怎么解决
    - 消息阻塞出现的原因是RabbitMQ提供了一种QOS（服务质量保证）功能，即在非自动确认消息的前提下，限制信道上的消费者所能保持的最大未确认的数量（可以通过prefetchCount属性设置）。可以理解为consumer前面加了一个缓冲容器，容器最大容量是prefetchCount。当缓冲容器等于prefetchCount时，RabbitMQ则不再进行投递，导致消息阻塞。
    - 解决方法：将consumer消费消息的代码放进try catch代码块中，若出现异常将消息重新投放到队列中，没有异常则手动确认消费，避免消息一直阻塞在缓冲容器里。
  - 如何解决RabbitMq重复消费
    - 1.消费端处理消息的业务逻辑保持幂等性。
    - 2.保证每条消息都有唯一编号（消息ID）且保证消息处理成功与去重表的日志同时出现。利用一张日志表记录已经处理成功的消息ID。
  - **1.** rocketMQ为什么要用消费组，起什么作用？  
    - 答：①：消息消费负载均衡 ②：故障容错 
  - **2.** RocketMQ同一个消费组内的消费者订阅量不同tag，会有问题吗？  
    - 答：会出现丢消息的情况。（发现不相同tag，offset直接跳过非查找的tag，导致消息丢失）
  - **3.** RocketMQ 消费者拉取一批消息，其中部分消费失败了，偏移量怎样更新？  
    - 答：rocketmq采用最小位点提交机制，例如消息消费线程池中的三个消费线程t1,t2,t3分别在处理消息偏移量1,2,3的消息，
       - 由于是并发消费，如果t3线程将msg3先消费完成后，会向服务端提交msg1的偏移量。如果在此期间消费者发生重启，则会导致重复消费。
  - **4.** 消息堆积了怎么办？  
    - 答：增加相同topic的队列数或者再开一个topic进行消息迁移消费。
  - **5.** 如何让 RocketMQ 保证消息的顺序消费？  
    - 答：生产者 设置将统一事务下的消息投放至同一个队列里面。消费者 并发模式改为顺序模式。
  - **6.**  RocketMq是push模型还是pull模型？
    - 答：rocketmq不管是推模式还是拉模式底层都是拉模式，推模式也是在拉模式上做了一层封装。
  - **7.** RocketMq为什么采用主动拉取消息而不使用事件监听方式？  
    - 如果broker主动推送消息的话有可能push速度快，消费速度慢的情况，那么就会造成消息在 Consumer 端堆积过多。 而 pull 的方式可以根据当前自身情况来 pull，不会造成过多的压力而造成瓶颈。所以采取了 pull 的方式。
  - **8.** 如何保证RocketMQ不丢失消息  
    - * 生产阶段：
    -   * 生产者通过网络发送消息给broker，当broker收到之后，将会返回确认响应信息给 Producer。
    -     所以生产者只要接收到返回的确认响应，就代表消息在生产阶段未丢失。当出现网络问题，我们可以设置合理的重试次数。
    - * Broker存储阶段：
    -   * 分为异步刷盘和同步刷盘，若想保证Broker端不丢消息，可以通过修改配置改为同步刷盘。
    - * 消费阶段：
    -   * 消费者从 broker 拉取消息，然后执行相应的业务逻辑。一旦执行成功，将会返回 ConsumeConcurrentlyStatus.CONSUME_SUCCESS 状态给 Broker。
      如果Broker未收到消费确认响应或收到其他状态，消费者下次还会再次拉取到该条消息，进行重试。这样的方式有效避免了消费者消费过程发生异常，或者消息在网络传输中丢失的情况。
  - **9.** RocketMq的存储机制了解吗？  
    - 答：RocketMq采用文件系统存储消息，并采用顺序写写入消息，使用零拷贝发送消息，极大得保证了RocketMq的性能。
  - **10.** 零拷贝是什么？rocketmq是怎么实现的？  
    - * 零拷贝：
    -   * 简单来说就是减少【用户态与内核态的上下文切换】和【内存拷贝】的次数的方案。通常有2种：mmap + write和sendfile
  - * rocketmq是怎么实现的：
    -   * mmap + write + Page cache

- K8S
  - Docker CNI 的实现
  - Docker 底层、多阶段构建
  - k8s组 件，pod创建的过程，operator是什么? 3、docker是怎么实现的，底层基石 namespace和cgroup。4、k8s的workload类型，使用场景，statefulset你们是怎么用 的? 5、limit和request，探针，一般怎么排查pod问题，查看上次失败的pod日志。6、sidecar是什么，怎么实现的? 7、pv，pvc，动态pv怎么实现 8、k8s的声明式api 怎么实现的，informar源码。9、cicd，发布模式。10、svc的负载均衡、服务发现， ipvs与iptables。
  - list和watch区别，机制的原理；如何用deployment模拟daemoset；service 都有哪些类型，如果应用需要粘性会话如何配置
    - watch是tcp连接维持吧，list一般只是一次请求
    - deployment可以设置pod的node亲和度完成deamonset的模拟 
      - 可以在Deployment的PodAntiAffinity中设置labelSelector，使得同一labelSelector下的Pod不会被调度到同一节点上，从而达到模拟DaemonSet的效果。 
      - hostPort - The kubernetes scheduler will be unable to schedule more than 1 pod on same host and in this way all nodes have at least one pod scheduled.
    - service配置sessionAffinity：clientIP
  - https://github.com/cloudnativeto/sig-kubernetes/issues/37
  - kubernetes DaemonSet是如何进行版本管理的
    - ControllerRevision 是专门用来管理某种Controller对象的版本的 `kc get controllerrevision -n kube-system`
  - kubernetes DaemonSet是如何保证pod只在一个节点上运行并且保证数量是1
    - 首先DaemonSet Controller会从Etcd里获取node的节点列表, 之后一个一个区遍历检查,看看node是不是有一个特定的label(这个label是创建DaemonSet 时指定的,即spec.template.metadata.labels) , 如果有这个pod就不管,没有就创建, 多了就删
    - 在创建pod的时候, 会指定pod在指定的node上创建, 即在创建pod的时候DaemonSet 会自动在pod的API对象上加一个nodeAffinity字段 , 这个字段的作用就是指定pod只能运行在当前节点
  - 一个pod创建流程
    - 可通过kubectl或yaml创建pod请求
    - apiserver接收到请求后,会存储pod数据到etcd
    - scheduler的watch接口会从apiserver处监听到新建pod的信息，scheduler会根据集群的整体信息，选出最优的node进行调度,会通过apiserver将信息写到etcd里
    - 目标node上的kubelet通过apiserver监听到新建的pod,会去调用Container Runtime Interface (CRI) 创建相应pod.
  - pod中pending状态，是什么原因产生的，pod出现问题，排查思路
    - pending原因
      - 节点资源不足
      - 不满足 nodeSelector 与 affinity
      - Node 存在 Pod 没有容忍的污点
      - kube-scheduler 未正常运行
      - 镜像不存在
    - 排查思路
      - kubectl describe pod 查看具体信息
      - 到相应node上查看具体日志
  - 你们监控用的什么，怎么利用普罗米修斯监控pod信息，k8s状态，如果来设计相关的监控如何落地
    - 使用promethues-opreator ，数据持久化，如果集群过大可以考虑使用thanos高可用。
    - pod 的metrics信息已经集成到的kubelet,直接用cAdvisor提供的metrics接口获取到所有容器相关的性能指标数据。
    - 自定义相关模板 通过grafana展示。（grafana上有许多优秀的模板）
  - 如果利用k8s实现滚动更新，我说的配置文件机制
    - deployment strategy RollingUpdate
  - statefulset是怎么实现滚动更新的？
    - 多个pod时，会按照顺序(序列号)滚动更新，每一个 Pod 都正常运行时才会继续处理下一个 Pod。
  - kubectl exec实现的原理？
    - -v=7 可以看到详细信息
    - 首先会读取config文件 ，生成GET/POST请求 去访问apiserver
    - apiserver会向kubelet发起连接
  - 了解过 endpointslice吗？ 怎么实现的？
  - 容器的驱逐时间是？
    - node notready时，默认驱逐时间是5min，可修改，是由kube-controller-manager的pod-eviction-timeout控制的。
    - node资源不足时也会发生驱逐，是按照qos等级来驱逐的。
  - 节点notready是什么导致的？ notready会发生什么？
    - notready原因
      - kubelet异常 不能和apiserver通信
      - 网络异常
      - kubelet version
      - kernel
    - notready会发生什么
      - node notready 5min,pod 会驱逐到其他节点。
  - api-server到etcd怎么保证事件不丢失？
  - sidecar要保证顺序启动怎么保证？几种方式可以做到？
  - 有了解过qos吗？ 怎么实现的？
    - qos三种 Guaranteed, Burstable, and Best-Effort，它们的QoS级别依次递减。
      - Guaranteed 如果Pod中所有Container的所有Resource的limit和request都相等且不为0，则这个Pod的QoS Class就是Guaranteed。
      - Best-Effort 如果Pod中所有容器的所有Resource的request和limit都没有赋值，则这个Pod的QoS Class就是Best-Effort.
      - Burstable 除了符合Guaranteed和Best-Effort的场景，其他场景的Pod QoS Class都属于Burstable。
      - node资源不足时会按qos级别驱逐pod。 最先驱逐的是Best-Effort ,重要组件一定要设置limit和request.
  - 详述kube-proxy原理
    - 监听 API server 中 service 和 endpoint 的变化情况，并通过 iptables 等来为服务配置负载均衡
    - kube-proxy的作用主要是负责service的实现。 service另外一个重要作用是，一个服务后端的Pods可能会随着生存灭亡而发生IP的改变，service的出现，给服务提供了一个固定的IP，而无视后端Endpoint的变化。
    - kube-proxy 模式
      - userspace 已弃用
      - iptables 大规模下会有性能问题 且不支持会话保持
      - ipvs
  - k8s的pause容器有什么用。是否可以去掉
    - 为pod中的多个容器提供共享网络空间，实现pod里容器间的通信。
    - 主要有两个职责：
      - 是pod里其他容器共享Linux namespace的基础
      - 扮演PID 1的角色，负责处理僵尸进程
  - k8s的service和ep是如何关联和相互影响的
    - service中有selector时才会创建endpoints.
    - kube-proxy 会监视 Kubernetes 控制节点对 Service 对象和 Endpoints 对象的添加和移除。
    - 只要服务中的pod集合发生更改，endpoints就会被更新。
  - StatefulSets和operator区别
    - StatefulSet是为了解决有状态服务的。
    - opertator用来扩展k8s api,自定义crd。

- OS
  - 说一下进程的创建过程
    - 进程号和PCB什么关系
    - 说一下进程的调度过程
    - 进程调度的算法
    - 说一下FCFS的缺点
    - 说一下时间片轮转的缺点
    - 时间片大小是怎么确定的
  - 现代计算机一般用的什么调度算法
    - 说一下多级反馈队列算法
    - 每个优先级队列使用的是什么调度策略
    - 多级反馈队列支持优先级调度吗
  - 管道分为哪些
  - 用的比较多的通信方式有哪几种
  - 文件能用来作为进程间通信的方式吗
  - linux如何查看僵尸进程
    - 如何杀死一个僵尸进程
    - 有kill -9杀不掉的进程的情况吗

- Misc
  - CSP和Actor分布式模型的区别、内存对齐
  - 战争迷雾怎么实现、共识算法
  - 连接池
    - 介绍连接池常用的参数，最大连接数，最小存活数这些意义，为什么要有这些
    - 当链接超过最大连接数怎么处理，等待有空闲连接还是创建一个继续给出，比较两 者的优劣
    - 连接池清理链接的逻辑，如何优化的
    - 当连接池中有一些链接不可用了怎么办，如何保证这些连接的可用
    - 当出现下游某个实例挂掉了，连接池应该怎么处理
    - 对比 mysql redis http 连接池的实现
    - 线程池的核心线程数一般怎么设置? 为什么讲Netty线程池的线程数设置为CPU核数*2
      - 多线程的本质是为了提升程序的性能，总体来说有两个最核心的指标，一个延迟，一个吞吐量
      - 要降低延时，就是要提高CPU的处理能力。而提高吞吐量，就是要提高IO读写效率
      - 程序分为是I/O密集型任务和CPU密集型任务
        - CPU密集型任务而言，理论上“线程的数量 = CPU核数”就是合适的。但是，在实际应用中的线程数量一般会设置为“CPU核数 + 1”。因为线程有可能因为内存页失效或其他原因导致阻塞，多设置一个线程可以保证CPU的利用率
        - 而对于I/O密集型任务而言，我们假设CPU计算和I/O操作的耗时比是 1:1，那么2个线程是最合适的。如果CPU计算和I/O操作的耗时比是 1:2，也就是说3个线程是合适的，这样CPU和I/O设备的利用率都可以达到100%。
      - 最佳线程数 = 1 +（IO耗时/CPU耗时）
  - 有一个请求队列,有读者线程和写者线程 在同时操作这个共享的请求队列,属于什么样的读写模型 ？
  - 一写多读模型的情况下怎么解决读写冲突的问题？加锁是一种方案,但是会影响性能,有没有更好的办法？
  - 存字符串用unordered_map还是用map好？为什么？要怎么优化？
  - 有一个请求队列,有读者线程和写者线程 在同时操作这个共享的请求队列,属于什么样的读写模型 ？
  - 一写多读模型的情况下怎么解决读写冲突的问题？加锁是一种方案,但是会影响性能,有没有更好的办法？
  - 线程有自己私有的栈，那么这个栈的内存是被分配到哪里的？是放在进程所属的内存里面，还是说放在独立于进程外部的内存中？
  - 认证 (Authentication) 和授权 (Authorization)的区别是什么？
  - 什么是 Cookie ? Cookie 的作用是什么?如何在服务端使用 Cookie ?
  - Cookie 和 Session 有什么区别？如何使用 Session 进行身份验证？
  - 如果没有 Cookie 的话 Session 还能用吗？
  - 为什么 Cookie 无法防止 CSRF 攻击，而 token 可以？
  - 什么是 Token?什么是 JWT?如何基于 Token 进行身份验证？
  - 什么是 OAuth 2.0？
  - 什么是 SSO(单点登录)？

- ES
  - es 索引的过程 切词怎么切 切词算法 降噪
    - es（Elasticsearch）是一款基于Lucene的分布式搜索引擎，它的索引过程主要包括以下几个步骤：
      - 文本分析（Tokenization）：将文本切分成一个个的词（Token），这个过程叫做切词。切词的目的是将文本中的词语提取出来，方便后续的搜索和分析。在es中，切词是由分析器（Analyzer）来完成的。es提供了多种分析器，如Standard Analyzer、Whitespace Analyzer、Simple Analyzer、CJK Analyzer等等。每种分析器都有自己的切词算法和降噪规则。
      - 词语归一化（Token Normalization）：将词语转化为小写形式，去掉停用词（Stopwords），以及进行词干提取（Stemming）等操作。这个过程可以让搜索更加准确和快速。
      - 建立倒排索引（Inverted Indexing）：将词语和文档的对应关系记录下来，建立倒排索引。倒排索引是一种数据结构，它可以快速地根据词语查找到包含这个词语的文档。
    - 在es中，切词算法主要有两种：基于规则的切词算法和基于统计的切词算法。基于规则的切词算法是根据一些规则来进行切词的，比如根据空格、标点符号等来切分文本。而基于统计的切词算法是通过分析大量的语料库来学习词语的分布和规律，从而进行切词。
    - 降噪是指在切词过程中去掉一些无意义的词语，如停用词、标点符号等。在es中，可以通过配置分析器来进行降噪。es内置了一些常用的停用词列表，也可以自定义停用词列表。
  - 索引，倒排索引，切词，如何根据 doc id 有没有出现某个 token
  -  es 索引的过程

- Design Pattern
  - 代理模式和适配器模式有什么区别
    - 代理模式和适配器模式是两种常用的设计模式，它们的区别主要体现在以下几个方面：
    - 作用不同：代理模式是为了控制对对象的访问，而适配器模式是为了解决接口不匹配的问题。
    - 解决问题的角度不同：代理模式是从外部控制访问，保护目标对象，而适配器模式是从内部改变对象接口，让其能够适配客户端的要求。
    - 实现方式不同：代理模式通常使用面向对象的继承或者组合方式实现，而适配器模式则通常使用对象组合方式实现。
    - 适用场景不同：代理模式适用于需要对对象进行控制和保护的情况，例如远程代理、虚拟代理等。适配器模式适用于需要将一个类的接口转换成客户端期望的另一个接口的情况，例如旧系统的升级改造、不兼容接口的统一等。

- Design
  - 抛硬币，先抛到正面算赢，否则轮流抛。问先抛的人获胜的概率。
    - 设先抛先吃的概率为p1， 后抛先吃的概率为p2. 那么有：p1 = 1/2 + 1/2 * p2 and p1 + p2 = 1
  - 概率 p 生成 0，1-p 生成 1，如何 1/2 概率生成 1
    - 让该随机数生成器生成两个数，那么序列是00,01,10,11概率分别为 p*p,p*(1-p),(1-p)*p,(1-p)*(1-p)
      - 很明显，这四种情况中存在两个独立的事件概率是相等。也就是01和10，那么我把01看成是0,10看成是1，那么他们输出的概率均为p(1-p)，其他的情况舍弃。这样就得到了0和1均等生成的随机器了。
      def random_index():
        rate = [1, 9]
        start = 0
        index = 0
        random = random.randint(1, sum(rate))
        for index, scope in enumerate(rate):
          start += scope
          if random <= start:
            break
        return index
    - 随机数生成函数f(),返回0的概率是 60%， 返回1的概率是 40%。
  - 以 1/N 的概率产生 1~N 之间的数
    - 采用位运算，i个二进制位随机选择0或者1，构成0~2^i的数，这些数字是等概率出现的
      - 由 random index产生 rand1函数，rand1等概率生成0和1
      - 计算整数n的二进制所拥有的位数k，k = 1+logn
      - 调用k次 rand1产生随机数
  - 函数只能返回1-7的随机数，请用这个函数返回1-5，要求平均 4.
    - 可以通过拒绝采样来解决。我们可以生成两个随机数，如果它们都是偶数，则丢弃并重新生成，否则返回它们的平均值加 1。这样可以确保返回的数字在 1 到 5 之间，并且平均值为 4。
    - def random_1_to_5():
        while True:
          num1 = random.randint(1, 7)
          num2 = random.randint(1, 7)
          if num1 % 2 == 0 and num2 % 2 == 0:
              continue
          else:
              return (num1 + num2) // 2 + 1
  - 如何等概率的随机数 0出现1次，1出现2次，2出现三次 。。。
    while true:
      m = rand(size)
      n = rand(size)
      if m + n < size
        return m+n
  - rand5() -> rand7(), rand7() -> rand10()
    - rand5() - 1 得到离散集合 {0, 1, 2, 3, 4}, 每个数的概率是 1/5. 而(rand5 - 1)*5 得到离散整数{1, 5, 10, 15, 20}， 每个数概率是1/5. 则(rand5 - 1)*5 + rand5分布在1~25之间，每个数的概率是1/25.
      ```java
        // 首先得到一个数
        int num = (rand7() - 1) * 7 + rand7();
        // 只要它还大于10，那就给我不断生成，因为我只要范围在1-10的，最后直接返回就可以了
        while (num > 10){
            num = (rand7() - 1) * 7 + rand7();
        }
        return num;
     ```
    - [Improve](https://leetcode.cn/problems/implement-rand10-using-rand7/solution/xiang-xi-si-lu-ji-you-hua-si-lu-fen-xi-zhu-xing-ji/)
      // 首先得到一个数
      int num = (rand7() - 1) * 7 + rand7();
      // 只要它还大于40，那你就给我不断生成吧
      while (num > 40)
          num = (rand7() - 1) * 7 + rand7();
      // 返回结果，+1是为了解决 40%10为0的情况
      return 1 + num % 10;
    - Again
      int num = (rand7() - 1) * 7 + rand7();
      // 如果在40以内，那就直接返回
      if(num <= 40) return 1 + num % 10;
      // 说明刚才生成的在41-49之间，利用随机数再操作一遍
      num = (num - 40 - 1) * 7 + rand7();
      if(num <= 60) return 1 + num % 10;
      // 说明刚才生成的在61-63之间，利用随机数再操作一遍
      num = (num - 60 - 1) * 7 + rand7();
      if(num <= 20) return 1 + num % 10;
  - 已知有个rand7()的函数，返回1到7随机自然数，让利用这个rand7()构造rand10() 随机1~10
    - 发现(rand7()-1)*7+rand7(),可以等概率的生成1到49 只要把11-49砍掉就可以了。不过这样的效率比较低。可以砍掉41-49，然后在把1-40映射到1-10（例如模10），那么问题也就解决了
  - 调用RANDOM(0, 1)实现RANDOM(a, b)
    - 这里的RANDOM(0, 1)是指等概率产生0或1，显然，RANDOM(a, b) = a + RANDOM(0, b-a)
  - 设计存储结构(FST，前缀树+后缀树) 
    - FST，即有限状态转换机（Finite State Transducer），是一种常见的存储结构，用于表示一组字符串集合。它可以看作是前缀树和后缀树的结合体，具有前缀树的前向搜索和后缀树的后向搜索的优点。
    - 简单的 FST 的设计：
      - 状态集合：一个状态表示一个字符串的前缀或后缀，状态集合由根节点和所有字符串的前缀和后缀构成。
      - 转移函数：从一个状态到另一个状态的转移函数，可以是字符或字符串的映射关系。对于前缀树部分，可以使用字符映射，对于后缀树部分，可以使用字符串映射。
      - 终止状态：表示一个字符串是否是集合中的一个元素。对于前缀树部分，所有以根节点为前缀的字符串都是集合中的元素，对于后缀树部分，所有以叶子节点为后缀的字符串都是集合中的元素。
  - 把所有评论放到内存里，怎么设计数据结构，存储并排序
  - 设计一个每秒80万qps的过滤器. 过滤器用redis实现，宕机期间数据怎么恢复
  - 设计一个下单 扣减库存的分布式应用，请求超时了怎么办，一直重试超时了怎么办
  - 只有写锁实现读写锁
  - 如果做一个翻译服务，翻译能力来自于供应商，如何从技术上对几家（A、B、C）供应商作出评估？
  - 如果几家都要接入，且各家之间的翻译能力都各有优劣，那应该如何去搭建这个服务的框架？- 调度器 - 数据采集 / 反馈机制，帮助调度器更好地工作 - 可扩展性，固化供应商的接入标准，方便未来扩展更多供应商选择
  - 除了回答的这些方面，一个服务的设计还需要注意什么？- 正常服务应该提供的网关，包括鉴权、限流、多租户 - 提供给外部的服务需要注意 SLA，SLA 则围绕日志、监控、Tracing 做文章
  - 一副扑克牌中随机取 5 张，取到顺子的概率是多少？- Hint 1：一种花色有多少种顺子？9 种 - Hint 2：一个顺子有 5 张牌，有多少种组合可能？4 ^ 5 种 - Hint 3：分子已经知道了，分母怎么表示，n 张取 m 张怎么表示？
  - 掷骰子，游戏规则：希望结果尽可能大，如果对第一次的结果不满意可以掷第二次，但是第一次结果就作废了，以第二次的结果为准。这个掷骰子结果的数学期望是多少呢？
    - Hint 1：如果第一次扔到 6，还考虑扔第二次吗？如果第一次扔到 1 考虑吗？
    - Hint 2：那什么情况考虑扔第二次，什么情况不考虑？
  - 输入两个整数 a 和 b，输出他们相除的结果，如果有循环小数用括号表示。如：- a=-1，b=2，输出 "-0.5" - a=1，b=3，输出 "0.(3)" - a=10，b=80，输出 "0.125" - a=-100，b=10，输出 "-10"


- 笔试以及设计
  - 设计一个线程池
  - 求a的n次方（不能用O(n)复杂度的）
  - LRU  缓存设计
  - 最长回文串
  - 根据前序中序恢复二叉树
  - 数组中重复的数字。
  - 二叉树的中序遍历，不用递归。中序遍历用的Morris遍历
  - 蛇形打印二叉树
  - 密码本由一个字符串数组组成，不同元素之间使用空格隔开，每一个元素代表密码本每一页的密码。[ref](https://mp.weixin.qq.com/s/CVRx69HDSOFCK0BAnwUszA)
    - password是一个有效密码，****当且仅当password[:-1]是一个有效密码。
    - 需要对原来的字符串数组password_lst按照字典序进行排序，就可以保证在password进行判断时，password[:-1]已经被判断过了。
    for password in password_lst:
    if password[:-1] in valid_set:
        valid_set.add(password)
        ans = password
  - 停车场有一横排车位，0 代表没有停车，1 代表有车。至少停了一辆车在车位上，也至少有一个空位没有停车。为了防剐蹭，需为停车人找到一个车位，使得距停车人的车最近的车辆的距离是最大的，返回此时的最大距离。
    - 所停的车位有两种情况需要考虑：https://mp.weixin.qq.com/s/pFerB4bnLB1P4Mn9ROjicQ
      - 左边没有车或者右边没有车，即停在边上的位置
      - 左边和右边均有车，即停在两车之间
    - 为了使得所停位置和最近的车距离最大，我们贪心地思考这个问题：
      - 对于第一种停车情况，我们一定是停靠在最边上，才能使得本车距离其左边或右边最近的车最远
      - 对于第二种停车情况，我们一定是恰好停在左右两车之间正中间的位置，才能使得本车距离左右两车的距离均远。
    - 我们首先找到最左边的1和最右边的1的位置（索引），分别记为left和right
    - 根据left和right计算按照第一种情况停车，能得到的最大距离，即ans = max(left, n-1-right)
    - 然后遍历剩下的区间lst[left+1:right+1]，每找到一个1，就计算其位置i和上一个1的位置pre之间的距离的一半(i-pre)//2，即为停在区间lst[pre:i+1]中的车，能取得的距离左右辆车的最大距离，再将该结果和原先的ans比较并更新即可。
  - 数组A1 2和数组B2 3是一个关系圈，A能通过2找到3，数组A1 2和数组B2 3和数组 C 3 5也是一个关系圈，给一个二维数组求关系数
  - https://leetcode-cn.com/problems/find-peak-element/
  - https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock/
  - https://leetcode-cn.com/problems/coin-change-2/
  - https://leetcode-cn.com/problems/first-missing-positive/
  - https://leetcode-cn.com/problems/permutations/
  - https://leetcode-cn.com/problems/sorted-merge-lcci/
  - https://www.nowcoder.com/practice/35119064d0224c35ab1ab612bffee8df
  - 定义 Redis 跳跃表的结构，再实现一版它的插入方法。
  - https://docs.qq.com/doc/DRWpDSlRYZ0lIUWhP?u=cd4fd4c4ef494951aa47b3cc433a1115
    - Lc No.1372 二叉树最长交错路径
    - Lc No.1353 最多参加会议数目


- Tips:
  - 面试后听录音重新 Review 面试，可以从面试官的角度听自己的回答，也方便整理面试经历。
  - 一、二、三轮的面试官都是团队中的什么角色呢
  - 作为管理者如果看到团队中的技术氛围比较欠缺，会考虑什么样的手段（去提升）呢
  - 正常业务的 CI/CD 里面都做了/集成了多少测试或检查
  - 研发对开发质量的保障是如何完成的，测试和覆盖率是否有要求 
  - 了解面试部门的基本情况？部门内微服务的数量？每个研发大概会负责多少服务的开发工作







