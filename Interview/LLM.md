- 介绍CUDA的存储结构。 
- 说说CUDA对主存的抽象。 
- 介绍CUDA缓存。 
- 介绍CUDA的线程/线程块/线程网格的概念。 
- 介绍CUDA的wrap。 
- GPU优化卷积有什么策略。 
- GPU优化转置有什么策略。 
- GPU优化矩阵乘有什么方式。 
- 介绍flash attention的优化（1和2都需要）。（要求） 
- 介绍并行排序，能写一下吗。 
- CUDA程序怎么profile。 
- 介绍tensorcore。 
- 说一下你知道的卡的参数和通信参数。（要求） 
- NVLink介绍一下，RDMA介绍一下。 
- 你有什么程序性能优化的经验。 
- 介绍常见模型压缩的方法（量化剪枝蒸馏）。 
- 量化分几种。 你实际用过什么量化。
- 介绍一下tensorrt的部署流程。 
- 介绍一下tensorrt量化和自定义算子的手段。 
- 介绍一下ONNXruntime的系统图。 
- 介绍一下TVM的部署流程以及它会用到什么优化。 
- 介绍TVM搜索超参的行为。 
- 分布式训练包括什么手段。 
- 数据并行和分布式数据并行区别。 背一下相关的通信指标。 
- 模型并行中流水线空泡说一下怎么做。 
- FSDP，zero的三阶段说一下。 
- 集合通信原语说一下，all reduce/gather优化。
- 多节点如何通信优化。
- 思维链和思维树的区别，思维树的每个节点是等可能的吗，会有无限的路径吗，思维树的结果是怎么得出来的。
  - 建议回复：不总是相等，取决于ToT的策略和评估函数所以ToT一般是控制深度，模式上类似于BFS
- Gbdt和xgboost的区别
  - XGBoost是对GBDT的改进和扩展，它提供了更高的效率、更好的性能、正则化技术、内置特征选择等功能。
    - (1)正则化：
      - GBDT使用基本的树模型，并在每一轮迭代中逐渐增加树的复杂性。它使用简单的正则化技术，如叶子节点的最小样本数限制，来防止过拟合。
      - XGBoost引入了正则化技术，包括L1和L2正则化，以减少过拟合风险。它还使用了二阶导数信息来提高训练的稳定性。
    - (2)高效性：
      - XGBoost通过多线程和分布式计算提供了更高的训练效率。它实现了高度优化的数据存储和计算，以减少内存使用和加速训练过程。
      - GBDT通常以串行方式训练，训练时间可能较长，特别是在处理大规模数据时。
    - (3)缺失值处理：
      - XGBoost能够自动处理缺失值，无需手动进行处理。
      - 在GBDT中，需要在数据预处理阶段手动处理缺失值，通常通过填充或删除缺失值。
    - (4)内置特征选择：
      - XGBoost具有内置的特征选择功能，它可以估计每个特征的重要性，并根据其重要性进行特征选择。GBDT通常需要手动进行特征选择或依赖其他特征选择方法。
    - (5)求导优化：
      - GBDT只需要对目标函数求一阶导，xgboost要求二阶导。
- Lstm的特点
  - (1)门控机制：
    - LSTM引入了门控机制，包括遗忘门、输入门和输出门，这些门控制着信息的流动和保存。遗忘门决定哪些信息应该被遗忘，输入门控制哪些信息应该被添加到记忆单元，输出门控制什么信息 应该传递到下一个时间步。这种机制有助于控制信息的流动，提高了模型的训练效率。
  - (2)长期记忆：
    - LSTM的主要特点是能够捕捉和维护长期依赖关系，它在处理序列数据中表现出色。传统的RNN存在梯度消失问题，导致难以学习长序列的依赖关系，而LSTM通过设计具有记忆单元的结构来解  - 决这个问题，允许信息在长时间内保持不变。
  - (3)平行化训练：
    - LSTM具有良好的并行性，可以加速训练过程，特别是在GPU上进行训练。这有助于处理大规模数据和加速深度学习模型的训练。
- Transformer的最重要的特点，对比CNN的效果
  - 最重要的特点是自注意力机制。
   - 对比CNN，transformer更注重全局特征，特征之间能并行计算，CNN更注重局部特征，图像分类领域中，在图像数量充足的情况下，tranformer的效果通常比CNN好
- ReLU激活函数的优缺点，怎么改进
  - 优点：
  - (1) 当特征值大于0时，可以避免梯度消失
  - (2)计算简单
  - 缺点：
  - (1) 非零均值
  - (2)当特征值大量小于0时，可能引起梯度消失
  - (3)当特征值大于0时，非线性拟合能力可能下降
  - 改进：改用Leaky ReLU函数
- 样本不均衡的处理方法
  - (1)欠采样
  - (2)过采样
  - (3)平衡读取数据
  - (4)设置权重，对样本较少的数据设置较高的训练权重
  - (5)使用平衡损失函数，比如focal loss等
  - (6)数据增强
- 介绍Focal loss
  - Focal Loss 最初由物体检测领域的研究者提出，其主要目标是减轻模型在训练过程中对大多数背景类别的关注，从而更好地处理少数类别的样本。这种损失函数有助于提高模型对罕见类别的检测性能。
  - Focal Loss 的主要特点如下:
   - 关注难分样本：Focal Loss 通过调整样本的权重，更加关注难以分类的样本。通常情况下，容易分类的样本(大多数属于背景类别)会降低其权重，而难分类的样本(属于少数类别)会增加其权重。
   - 降低易分类样本的权重：通过调整损失函数，Focal Loss 能够有效地降低容易分类的样本(背景类别、样本数量多的类别)的权重，这样模型将更加关注罕见类别，从而提高了模型在罕见类别的检测能力。
   - Focal Loss 的引入有助于提高目标检测模型对于罕见目标的检测性能，减轻了类别不平衡问题对模型训练的影响。
- 大模型方向面试官关注的点：
  - 1. 遇到什么问题，样本怎么处理？参数怎么优化和修改？attention针对具体的场景怎么适配和优化。
  - 2. sft公式的推导？这块没有听清，不知道是不是sft？
  - 3. alpaca代码看懂
  - 4. norm的区别，先做加和再做norm还是先做norm再做加和。pe推导过程。层数和节点数哪个更重要。
  - 5. 大模型的token的embedding的初始化方法，比如高斯正态分布。
  - 6. 一定要动手：lora训模型->预测->人工标注->dpo或者plo的方式进行偏好排序优化，代替强化学习
- 多标签分类的损失函数
  - 多标签分类任务，即一个样本可以有多个标签，比如一张图片中同时含有“猫”和“狗”，这张图片就同时拥有属于“猫”和“狗”的两种标签 https://blog.csdn.net/qq_24193303/article/details/124711723
  - iou是怎么计算的，有什么变种 IOU是交并比，图像的交集除以图像的并集
  - 目标检测量化过程中，相比原模型，预测结果框的中心点不变，但是长宽变成原来的一半，可能是什么原因？
    - (1)后处理过程主要是NMS可能被改变了
    - (2)下采样: 这种情况通常与神经网络中的下采样(池化层或卷积层)有关。在深度卷积神经网络中，随着网络的层次加深，特征图的分辨率通常会减小。当特征图的分辨率减半时，预测结果的框的位置信息也会相应减半。
    - (3)特征图尺度变化: 如果检测器的不同层次的特征图具有不同的尺度，那么在不同特征图上预测的框可能会有不同的尺度。当选择来自不同层次的特征图进行检测时，预测框的尺度可能会发生变化。
    - (4)锚框的设计: 一些目标检测器使用预定义的锚框来进行目标定位。这些锚框通常具有不同的长宽比例和尺度。如果选择了具有不同尺度的锚框，那么预测结果中的框的尺度也会不同
- 大量无标签数据怎么用于加强模型训练效果，有哪些方法？
  - 对比学习；主动学习；借助chatgpt等大模型，因为其内置了强化学习、zero shot等方法；还要注重对hard样本、稀缺样本进行采样，验证效果
- 怎么解决小目标分类问题？
  - (1)转化为小目标检测问题
  - (2)使用transformer等模型学习更全面的特征信息
  - (3)加入SE-block等增强特征信息的模块
  - 数据增强
- 介绍模型量化
- 不改动模型结构的前提下，检测小目标的方法
  - 数据增强、多尺度特征融合、锚框(anchor boxes)调整、改进损失函数、集成学习、增大图像尺寸
- Mosaic数据增强，以及其作用
  - 增强数据多样性，提升模型泛化能力
  - 可以减少batch_size，降低显存，还能加快模型训练速度
- mAP的计算过程，以及mAP有什么不足
  - 不足:
    - (1)对类不平衡问题敏感：mAP在处理类别不平衡时，容易受到长尾效应的影响。某些少见类别的AP可能很低，从而影响整体的mAP。
    - (2)IoU阈值的设定问题：通常mAP计算时采用固定的IoU阈值(如0.5)，这种固定值可能无法全面反映模型的检测性能。对于不同的应用场景，不同的IoU阈值可能更合适。
    - (3)对极端预测的敏感性：mAP对预测结果中置信度极高但不准确的情况较为敏感，这些错误的高置信度预测会显著降低精度。
    - (4)忽略定位误差：mAP主要关注检测框的数量和位置是否正确匹配，忽略了检测框的定位精度。即使检测框的IoU稍微低于阈值，也会被视为FP。
    - (5)计算复杂度高：对于大型数据集和高分辨率图像，mAP计算过程复杂且耗时，特别是在需要多次评估和调试模型时。
  - 改进方向:
    - (1)改进IoU阈值策略：使用多个IoU阈值(如COCO评测中的mAP@[.5:.95])来更全面地评估模型性能，反映不同IoU下的检测效果。
    - (2)采用Focal Loss等方法 减少对类不平衡的敏感性，提高少数类的检测性能。
    - (3)其他评估指标：引入更多评估指标，如Precision@k、Recall@k、F1-score等，结合使用以获得更全面的性能评估。
- Yolov4对IOU loss的改进
  - GIOU、DIOU、CIOU

